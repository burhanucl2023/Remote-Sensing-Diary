[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Remote Sensing",
    "section": "",
    "text": "Welcome\nI am Burhan. Born and brought up in the beautiful valley of Kashmir. Yeah, we are famous for Beautiful Valleys, Mesmerizing Lakes, Cashmere Shawls & Wazwan (our local cuisine). Take a glimpse of my hometown through this elaborate Photo Gallery or the short one below.\n\n\n\n\nI am a Passionate Urban Spatial Enthusiast pursuing postgraduate studies at University College London (UCL), blending expertise in Urban Spatial Sciences and Civil Engineering. I have held mid-level management positions in both government and the public sector, specializing in the strategic development of road networks for underserved areas in India. My mojo revolves around crafting the future of transportation design, playing with spatial analytics, rocking disaster management scenarios, championing net-zero strategies, and setting the stage for cool public policies. Committed to driving positive change, seeking collaboration with like-minded professionals to shape a more sustainable future for cities and regions.\n\n\n\n\nGratitude: As I was away for the first five weeks, so had to catch up a lot in a very small amount of time. But, I would like to express my gratitude to my department (in general) and Dr Andrew MacLachlan (in particular) for guiding me through this and I hope I have managed to produce a good learning diary and met the expectations of my peers."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ahmad, Dr. Zia. n.d. “Geospatial Data Science in\nR.” Accessed March 9, 2024. https://zia207.github.io/geospatial-r-github.io/index.html.\n\n\nDarbari, Priyanka, and Manoj Kumar. 2022. “Satellite Image\nEnhancement Techniques: A Comprehensive\nReview.” In Proceedings of International\nConference on Communication and Artificial\nIntelligence, edited by Vishal Goyal, Manish Gupta, Seyedali\nMirjalili, and Aditya Trivedi, 431–47. Lecture Notes in\nNetworks and Systems. Singapore: Springer\nNature. https://doi.org/10.1007/978-981-19-0976-4_36.\n\n\nEarth Science Data Systems, NASA. 2020. “What Is Synthetic\nAperture Radar? | Earthdata.” Backgrounder.\nEarth Science Data Systems, NASA. April 10, 2020. https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar.\n\n\nEarthdata-Website. 2019. “What Is Remote Sensing? |\nEarthdata.” Backgrounder. Earth Science Data\nSystems, NASA. August 23, 2019. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n\n\nEdward J Hoppe, Brian Bruckno, Elizabeth Campbell, Scott T Acton, Andrea\nVaccari, Michael Stuecheli, Adrian Bohane, Giacomo Falorni, and Jessica\nMorgan. 2016. “Transportation Infrastructure Monitoring\nUsing Satellite Remote Sensing.” In Materials and\nInfrastructures 1. John Wiley & Sons, Inc. https://doi.org/10.1002/9781119318583.ch14.\n\n\nElachi, Charles, and van Zyl Jakob J. 2006. “Introduction to the\nPhysics and Techniques of Remote\nSensing.” In Introduction to the Physics and\nTechniques of Remote Sensing, 1–21. Hoboken, NJ, USA: John Wiley\n& Sons, Inc.\n\n\nGIPHY, dir. n.d. Space Satellite GIF by\nNASA - Find & Share on\nGIPHY. Accessed February 4, 2024. https://giphy.com/gifs/nasa-space-nasagif-3ohc0PkM8mVYfmBHz2.\n\n\n“Google Timelapse.” n.d. Accessed March 9,\n2024. https://earthengine.google.com/timelapse/.\n\n\nHassan, Fawzy, Gouda Salama, Esam Hamza, and H. Hussien. 2006.\n“GEOMETRIC CORRECTION OF REMOTE SENSING SATELLITE DIGITAL\nIMAGES USING MAPPING POLYNOMIAL OF DIFFERENT ORDERS.”\nThe International Conference on Electrical Engineering 5 (5):\n1–22. https://doi.org/10.21608/iceeng.2006.33672.\n\n\nLiu, Desheng, and Fan Xia. 2010. “Assessing Object-Based\nClassification: Advantages and Limitations.” Remote Sensing\nLetters 1 (4): 187–94. https://doi.org/10.1080/01431161003743173.\n\n\nMatin, Shafique, Mukunda Behera, and Surya Mohapatra. 2012.\n“Criteria-Based Approach to Suggest Alternative Road Network in\nPart of Ladakh Province Through Object Based Modelling:\nA GIS & Remote Sensing Method.” Journal of\nEnvironmental Research and Development 7 (January).\n\n\nNajafi, P., H. Navid, B. Feizizadeh, and I. Eskandari. 2018.\n“Object-Based Satellite Image Analysis Applied for Crop Residue\nEstimating Using Landsat OLI Imagery.”\nInternational Journal of Remote Sensing 39 (19): 6117–36. https://doi.org/10.1080/01431161.2018.1454621.\n\n\n“Remote Sensing By Satellite: Physical\nBasis, Principles, & Uses.”\n2023. April 7, 2023. https://eos.com/blog/remote-sensing/.\n\n\n“SIR-C/X-SAR Image Kliuchevskoi\nVolcano Comparison.” n.d. Accessed March 15, 2024. https://www.geo.mtu.edu/volcanoes/klyuchevskoi/images/kliuch-compare.html.\n\n\n“Synthetic Aperture Radar.” n.d. Accessed\nMarch 15, 2024. https://www.surveyar.co.uk/fs08-radar-sar.\n\n\nSynthetic Aperture Radar (SAR)\nTechniques and Applications. 2020. MDPI.\nhttps://doi.org/10.3390/books978-3-03936-123-6.\n\n\nTay, Cheryl W. J., Sang-Ho Yun, Shi Tong Chin, Alok Bhardwaj, Jungkyo\nJung, and Emma M. Hill. 2020. “Rapid Flood and Damage Mapping\nUsing Synthetic Aperture Radar in Response to Typhoon\nHagibis, Japan.” Scientific Data 7\n(1): 100. https://doi.org/10.1038/s41597-020-0443-5.\n\n\n“The Nature Conservancy.” n.d. Accessed\nFebruary 4, 2024. https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/.\n\n\nWeng, Qihao, and Dengsheng Lu. 2008. “A Sub-Pixel Analysis of\nUrbanization Effect on Land Surface Temperature and Its Interplay with\nImpervious Surface and Vegetation Coverage in Indianapolis,\nUnited States.” International Journal of Applied\nEarth Observation and Geoinformation 10 (1): 68–83. https://doi.org/10.1016/j.jag.2007.05.002.\n\n\nWhiteside, Timothy G., Guy S. Boggs, and Stefan W. Maier. 2011.\n“Comparing Object-Based and Pixel-Based Classifications for\nMapping Savannas.” International Journal of Applied Earth\nObservation and Geoinformation 13 (6): 884–93. https://doi.org/10.1016/j.jag.2011.06.008."
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "1  Week 1 - Basics",
    "section": "",
    "text": "2 Summary\nRemote sensing data finds numerous applications across diverse fields. It is used in agriculture for optimizing uses of fertilizers, prediction of crop yields,measuring soil moisture content, monitoring droughts, assessment of crop health, etc.\nSimilarly, in forestry it can be used for monitoring forest cover, tracking deforestation & controlling forest fires.Also, remote sensing is being used for checking the rapid urbanization, planning road networks, pre and post disaster preparedness & in many more fields.\nAlso, during my research regarding the use of remote sensing, I came across one of the works which discussed the application of remote sensing in route planning for road projects in challenging terrain (Mishra (2015)). This study delved into the effectiveness of remote sensing and Geographic Information Systems (GIS) in mapping road infrastructure in rugged landscapes. Various factors influencing road network construction and the resolution of associated challenges were examined within a specific context. Criteria encompassing major and subsidiary factors were assessed to select an appropriate model for comparing attributes and grading them based on their significance. All these examples together demonstrate how valuable remote sensing technology is across a wide range of fields.\nTransitioning from a Civil Engineering background to the realm of spatial science, particularly remote sensing, has been a thrilling journey. One notable application that resonates with me, especially concerning India, is the utilization of remote sensing for identifying “Unconnected Habitations.” These are isolated dwellings or small clusters of houses situated in regions lacking road access, electricity, and water supply. Typically nestled in mountainous terrains, these areas are predominantly inhabited by tribal communities. So, by leveraging remote sensing technology we could identify these remote settlements, facilitating the formulation of targeted policies aimed at fostering development within these underserved regions."
  },
  {
    "objectID": "week_1.html#what-is-remote-sensing-you-ask",
    "href": "week_1.html#what-is-remote-sensing-you-ask",
    "title": "1  Week 1 - Basics",
    "section": "2.1 What is Remote Sensing, you ask?",
    "text": "2.1 What is Remote Sensing, you ask?\nRemote sensing is like Earth’s Personal Observer, capturing information from afar. NASA defines Remote Sensing as acquiring information from a distance - Earthdata-Website (2019) . Also, Elachi and van Zyl (2006) define remote sensing as “the acquisition of information about an object without being in physical contact with it”. All this is achieved through sensors mounted on satellites, planes, drones, etc.\n\n\n\nSpace Satellite GIF by NASA - GIPHY (n.d.)"
  },
  {
    "objectID": "week_1.html#types-of-sensors",
    "href": "week_1.html#types-of-sensors",
    "title": "1  Week 1 - Basics",
    "section": "2.2 Types of Sensors ?",
    "text": "2.2 Types of Sensors ?\nRemote sensing employs two main types of sensors: Passive and Active.\nPassive sensors rely on sunlight reflected off the Earth’s surface. However, they are susceptible to interference from elements like clouds and atmospheric haze.\nActive sensors, on the other hand, emit signals directed towards the Earth, which bounce back to the satellite sensor. This allows active sensors to operate effectively at night and even penetrate through cloud cover, enhancing their versatility.\nThe choice between passive and active sensors depends on the specific environmental conditions and the type of data required for remote sensing applications. A basic difference of the two is shown in the below image explicitly\n\n\n\nDifference between passive and active sensors for remote sensing. Image © “The Nature Conservancy” (n.d.)"
  },
  {
    "objectID": "week_1.html#electromagnetic-spectrum",
    "href": "week_1.html#electromagnetic-spectrum",
    "title": "1  Week 1 - Basics",
    "section": "2.3 Electromagnetic Spectrum ?",
    "text": "2.3 Electromagnetic Spectrum ?\nRemote sensing is based on the principle that there is always an interaction between electromagnetic radiation and an object.Electromagnetic waves travel through the air and space, each with different wavelengths and frequencies. Some waves, like radio and infrared, have long wavelengths, while others, such as ultraviolet and x-rays, have short wavelength. Human eyes can only see a small part called visible light.\nDifferent types of radiation operate in various parts of the electromagnetic spectrum. Sensors can read different wavelengths, thus providing diverse information. Earth’s atmosphere blocks most wavelengths, allowing only radio waves, visible light, and some infrared. Instruments, like passive sensors in the optical window and active sensors using radio waves, help us understand our surroundings.\n\n\n\nElectromagnetic Spectrum, Source Earthdata-Website (2019)"
  },
  {
    "objectID": "week_1.html#resolutions",
    "href": "week_1.html#resolutions",
    "title": "1  Week 1 - Basics",
    "section": "2.4 Resolutions",
    "text": "2.4 Resolutions\nRemote sensing data encompasses four key resolutions:\n\nSpectral Resolution: It refers to the size of each raster cell or pixel, dictating the level of detail captured.\nSpatial Resolution: It defines defines the sensor’s capability to differentiate wavelengths, determining the number of bands recorded, with multispectral sensors typically capturing 3-15 bands and hyperspectral sensors capable of thousands.\nTemporal Resolution:It indicates the frequency at which an area is revisited, influencing the timeliness of data acquisition.\nRadiometric Resolution: It quantifies the information contained within each raster cell, with higher resolutions yielding greater sensitivity to variations.\n\n\n\n\nDiagram showing different Resolutions, Source Darbari and Kumar (2022)"
  },
  {
    "objectID": "week_3.html",
    "href": "week_3.html",
    "title": "3  Week 3 - Corrections",
    "section": "",
    "text": "4 Summary\nThis week’s session focused on rectifying raw satellite images, merging them, and enhancing their quality, particularly delving into the significance of atmospheric corrections in satellite image studies. It’s crucial to recognize that satellite images often suffer from distortions due to various factors which were discussed above, and these can compromise the accuracy of our analysis. To mitigate these distortions, the corrections are routinely applied as a prerequisite before conducting analysis. These corrections ensure that the images are properly aligned and scaled, laying a reliable groundwork for subsequent interpretation and extraction of meaningful data.\nI stumbled upon a research paper by Hassan et al. (2006), where they delve into examining how changes in the number of Ground Control Points (GCPs) and the degree of mapping polynomials affect the accuracy of the geometric correction process. They utilized the Root Mean Square Error (RMS) at the chosen GCPs to gauge the accuracy of their findings. The study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.\nSimilarly, the same image was corrected by using 16 Ground Control Points as shown below.\nThe study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.The results of the study with respect to GCP, RMS is shown below.\nAs I joined the Term quite late, so had to catch up with all in a short amount of time. But, as the lectures and the practical notebooks were crafted perfectly, so I was able to grasp most of the concepts. Regarding, this week, I understand the importance of covering corrections, despite their initial complexity, to ensure data quality and facilitate comparison between different images. Exploring how remotely sensed images can be manipulated reveals deeper layers of information beyond the surface data. Although I didn’t do the practical exercises this week, but I have gone through the code and have also checked the Ahmad (n.d.) as recommended & I found it valuable and I anticipate revisiting it in future."
  },
  {
    "objectID": "week_3.html#corrections",
    "href": "week_3.html#corrections",
    "title": "3  Week 3 - Corrections",
    "section": "4.1 Corrections",
    "text": "4.1 Corrections\nRemotely sensed data requires corrections to remove flaws which may be due to various factors like - atmosphere, sensor sensitivity, illumination conditions, distortions due to viewing angle,topographic conditions,etc.\n- Atmospheric Correction: It removes flaws caused in the remotely sensed data due to atmosphere.The atmosphere affects the incoming sunlight thereby leading to reflection, scattering and absorption of various parts of electromagnetic spectrum. Atmospheric correction is either relative or absolute. Relative atmospheric correction adjusts the data based on radiance values of target area with respect to neighboring area, while as, in absolute atmospheric correction we convert digital brightness values into scaled surface reflectance. This allows us to directly compare these scaled surface reflectance values across different regions of the planet, facilitating accurate analysis and interpretation of Earth’s surface characteristics and changes over time.\n- Geometric Correction: Geometric correction involves adjusting remotely sensed data to account for image distortions introduced by various factors such as the view angle (off-nadir), topography (e.g., non-flat terrain), wind (in aerial acquisitions), and the rotation of the Earth (in satellite imagery). This correction ensures that the satellite image aligns accurately with a coordinate reference system.\n- Topographic Correction: It deals with the effect of terrain variations on reflectance values.It requires sensor geometry and elevation data. After incorporating it, the accuracy and consistency of remote sensing data improves across different terrain conditions.\n- Radiometric Correction: This correction accounts for sensor-related factors such as variations in sensor sensitivity, illumination conditions, and atmospheric effects, ensuring that the resulting data accurately represents the physical properties of the observed features."
  },
  {
    "objectID": "week_5.html",
    "href": "week_5.html",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "",
    "text": "6 Summary\nThis week was for Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets.\n\nWhat is GEE?\n\nGEE is a cloud-based platform for processing large geospatial datasets.\nIt simplifies data access and analysis for researchers, policymakers, NGOs, and the public.\nGEE uses an API and web-based IDE for rapid prototyping and visualization.\nKey terminology includes objects (vectors, rasters, features), images (raster data), and geometries (points, lines, polygons).\n\nFunctionalities\n\nGEE facilitates spatial operations, machine learning tasks, and statistical analyses.\nIts functionalities include reducing imagery, accessing data from multiple sensors, and performing joins and intersections.\n\n\nLast year, shortly after arriving in London, one of my initial tasks was to explore the evolution of Canary Wharf from its roots as docks to its current status as a financial hub. I connected to the city a lot more after this exposure of the history. Let us look at the transformation of Canary Wharf from its origins as dockyards to becoming a bustling business district.You can witness this evolution through Google Timelapse “Google Timelapse” (n.d.), one of the products of GEE. Simply press play button to observe the journey through time\n\n\n\n\n7 Applications\nThere have been so advancment in remote sensing research and ease of doing research with satellite data because of GEE. So, I made a tree map of “What is the craze about GEE and which sectors has it impacted”.\n\n\n\nGEE the bridge that connects, Source - Author\n\n\n\n\n8 Reflections\nGEE presents an intriguing tool for analysis, showcasing the impressive strides in technology and data analysis. Its ability to swiftly process vast amounts of data quickly as compared to tools like SNAP and R, make it exceptionally useful and futuristic. The versatility of GEE is evident in its extensive data access and diverse range of applications, spanning from straightforward to intricate processing tasks. I firmly believe that GEE and cloud computing will revolutionize remote sensing research. Despite my prior experience in Python and R, exploring a new coding language like JavaScript piques my interest, prompting me to consider further learning opportunities.But, again, this entire course of MSc Urban Spatial Science has been an opportunity to go to uncharted territories and moving away from your comfort zone. And despite the demanding nature of the course, this exploration has been immensely enriching, largely thanks to the outstanding faculty at CASA, whom I consider are among the finest at Bartlett.\n\n\n\n\n“Google Timelapse.” n.d. Accessed March 9, 2024. https://earthengine.google.com/timelapse/."
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "2  Week 2 - Sensor Presentation",
    "section": "",
    "text": "Burhan"
  },
  {
    "objectID": "week_4.html",
    "href": "week_4.html",
    "title": "4  Week 4 - Policy",
    "section": "",
    "text": "5 Summary\nThis week, we delved into Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets. GEE simplifies high-performance computing for researchers, facilitating sharing of results with various stakeholders. It offers an API and web-based IDE for quick prototyping and visualization. Instead of downloading heavy satellite imagery, GEE can swiftly load datasets, including various types of satellite imagery, via its Data Catalog. GEE operates on client-side code execution, enhancing speed, and utilizes JavaScript. It distinguishes between raster data (images) and vector data (features), organizing them into Image Collections and Feature Collections, respectively."
  },
  {
    "objectID": "week_6.html",
    "href": "week_6.html",
    "title": "6  Week 6 - Working on Group Presentation",
    "section": "",
    "text": "I was assigned to the group at the very last moment & they had already decided on the topic “Jakarta - Sinking City”. So, I gave my inputs and we started working on the draft presentation on “Windows Slides” initially and finally moved to Xaringan."
  },
  {
    "objectID": "week_1.html#summary",
    "href": "week_1.html#summary",
    "title": "1  Week 1 - Basics",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 What is Remote Sensing, you ask?\nRemote sensing is like Earth’s Personal Observer, capturing information from afar. NASA defines Remote Sensing as acquiring information from a distance - Earthdata-Website (2019) . Also, Elachi and van Zyl (2006) define remote sensing as “the acquisition of information about an object without being in physical contact with it”. All this is achieved through sensors mounted on satellites, planes, drones, etc.\n\n\n\nSpace Satellite GIF by NASA - GIPHY (n.d.)\n\n\n\n\n1.1.2 Types of Sensors ?\nRemote sensing employs two main types of sensors: Passive and Active.\nPassive sensors rely on sunlight reflected off the Earth’s surface. However, they are susceptible to interference from elements like clouds and atmospheric haze.\nActive sensors, on the other hand, emit signals directed towards the Earth, which bounce back to the satellite sensor. This allows active sensors to operate effectively at night and even penetrate through cloud cover, enhancing their versatility.\nThe choice between passive and active sensors depends on the specific environmental conditions and the type of data required for remote sensing applications. A basic difference of the two is shown in the below image explicitly\n\n\n\nDifference between passive and active sensors for remote sensing. Image © “The Nature Conservancy” (n.d.)\n\n\n\n\n1.1.3 Electromagnetic Spectrum ?\nRemote sensing is based on the principle that there is always an interaction between electromagnetic radiation and an object.Electromagnetic waves travel through the air and space, each with different wavelengths and frequencies. Some waves, like radio and infrared, have long wavelengths, while others, such as ultraviolet and x-rays, have short wavelength. Human eyes can only see a small part called visible light.\nDifferent types of radiation operate in various parts of the electromagnetic spectrum. Sensors can read different wavelengths, thus providing diverse information. Earth’s atmosphere blocks most wavelengths, allowing only radio waves, visible light, and some infrared. Instruments, like passive sensors in the optical window and active sensors using radio waves, help us understand our surroundings.\n\n\n\nElectromagnetic Spectrum, Source Earthdata-Website (2019)\n\n\n\n\n1.1.4 Resolutions\nRemote sensing data encompasses four key resolutions:\n\nSpectral Resolution: It refers to the size of each raster cell or pixel, dictating the level of detail captured.\nSpatial Resolution: It defines defines the sensor’s capability to differentiate wavelengths, determining the number of bands recorded, with multispectral sensors typically capturing 3-15 bands and hyperspectral sensors capable of thousands.\nTemporal Resolution:It indicates the frequency at which an area is revisited, influencing the timeliness of data acquisition.\nRadiometric Resolution: It quantifies the information contained within each raster cell, with higher resolutions yielding greater sensitivity to variations.\n\n\n\n\nDiagram showing different Resolutions, Source Darbari and Kumar (2022)"
  },
  {
    "objectID": "week_1.html#applications",
    "href": "week_1.html#applications",
    "title": "1  Week 1 - Basics",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nRemote sensing data finds numerous applications across diverse fields. It is used in agriculture for optimizing uses of fertilizers, prediction of crop yields,measuring soil moisture content, monitoring droughts, assessment of crop health, etc.\n\n\n\nA split view comparing NDVI index values on the same field taken 5 days apart. Such a tremendous decrease in NDVI may be the result of water or heat stress, which can be tracked in EOSDA Crop Monitoring., Source\n\n\nSimilarly, in forestry it can be used for monitoring forest cover, tracking deforestation & controlling forest fires.Also, remote sensing is being used for checking the rapid urbanization, planning road networks, pre and post disaster preparedness & in many more fields.\n\n\n\nForest fire damage assessment in the Chillan region of Chile using remote sensing data and EOSDA LandViewer capabilities., Source “Remote Sensing By Satellite: Physical Basis, Principles, & Uses” (2023)\n\n\nAlso, during my research regarding the use of remote sensing, I came across one of the works which discussed the application of remote sensing in route planning for road projects in challenging terrain (Matin, Behera, and Mohapatra (2012)). This study delved into the effectiveness of remote sensing and Geographic Information Systems (GIS) in mapping road infrastructure in rugged landscapes. Various factors influencing road network construction and the resolution of associated challenges were examined within a specific context.Another, interesting use case scenario of remote sensing that came across during my reading was, early warning landslide system used by Satyam (2021) . The risk due to landslides is a major concern in hilly terrains across the world, especially in the changing climate and rapid urbanization. All these examples together demonstrate how valuable remote sensing technology is across a wide range of fields.\nBecause, I joined the course quite late, so I moved directly to using Google Earth Engine. Here is my work of loading the Sentinel-2 Data and then clipping it for Srinagar City.\n\n\n\nSrinagar City - Source: Sentinel-2 MSI: MultiSpectral Instrument, Level-1C “User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online” (n.d.)"
  },
  {
    "objectID": "week_1.html#reflections",
    "href": "week_1.html#reflections",
    "title": "1  Week 1 - Basics",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nTransitioning from a Civil Engineering background to the realm of spatial science, particularly remote sensing, has been a thrilling journey. One notable application that resonates with me, especially concerning India, is the utilization of remote sensing for identifying “Unconnected Habitations.” These are isolated dwellings or small clusters of houses situated in regions lacking road access, electricity, and water supply. Typically nestled in mountainous terrains, these areas are predominantly inhabited by tribal communities. So, by leveraging remote sensing technology we could identify these remote settlements, facilitating the formulation of targeted policies aimed at fostering development within these underserved regions.\n\n\n\n\nDarbari, Priyanka, and Manoj Kumar. 2022. “Satellite Image Enhancement Techniques: A Comprehensive Review.” In Proceedings of International Conference on Communication and Artificial Intelligence, edited by Vishal Goyal, Manish Gupta, Seyedali Mirjalili, and Aditya Trivedi, 431–47. Lecture Notes in Networks and Systems. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-0976-4_36.\n\n\nEarthdata-Website. 2019. “What Is Remote Sensing? | Earthdata.” Backgrounder. Earth Science Data Systems, NASA. August 23, 2019. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n\n\nElachi, Charles, and van Zyl Jakob J. 2006. “Introduction to the Physics and Techniques of Remote Sensing.” In Introduction to the Physics and Techniques of Remote Sensing, 1–21. Hoboken, NJ, USA: John Wiley & Sons, Inc.\n\n\nGIPHY, dir. n.d. Space Satellite GIF by NASA - Find & Share on GIPHY. Accessed February 4, 2024. https://giphy.com/gifs/nasa-space-nasagif-3ohc0PkM8mVYfmBHz2.\n\n\nMatin, Shafique, Mukunda Behera, and Surya Mohapatra. 2012. “Criteria-Based Approach to Suggest Alternative Road Network in Part of Ladakh Province Through Object Based Modelling: A GIS & Remote Sensing Method.” Journal of Environmental Research and Development 7 (January).\n\n\n“Remote Sensing By Satellite: Physical Basis, Principles, & Uses.” 2023. April 7, 2023. https://eos.com/blog/remote-sensing/.\n\n\nSatyam, Neelima. 2021. “Chapter 11 - Landslide Prediction and Field Monitoring for Darjeeling Himalayas: A Case Study from Kalimpong.” In Basics of Computational Geophysics, edited by Pijush Samui, Barnali Dixon, and Dieu Tien Bui, 165–88. Elsevier. https://doi.org/10.1016/B978-0-12-820513-6.00010-2.\n\n\n“The Nature Conservancy.” n.d. Accessed February 4, 2024. https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/.\n\n\n“User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online.” n.d. Sentinel Online. Accessed March 17, 2024. https://copernicus.eu/user-guides/sentinel-2-msi/processing-levels/level-1."
  },
  {
    "objectID": "week_4.html#summary",
    "href": "week_4.html#summary",
    "title": "4  Week 4 - Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\n\n4.1.1 Introduction\nFor this week’s challenge, I choose the city where I grew up in viz. Srinagar. Srinagar is the capital of Jammu and Kashmir, a state in northern India. Srinagar’s predicted population in 2024 is roughly 1.7 million (according to UN World Urbanization Prospects). It’s also worth noting that the Srinagar Metropolitan Region accounts for more than 75% of the urban population, indicating highly unbalanced urbanisation or macrocephaly.\nBefore we go any further, let me provide a brief historical overview of the city. Srinagar’s name has been linked with some of its most known historical stories. The words “Sri” mean “Goddess of Wealth” and “nagar” imply “city”. As a result, the city is famously known as the “City of Wealth”.Today, Srinagar stands as one of the world’s most coveted tourist destinations, yet it has a history that has shaped it into what it is now. According to certain renowned historians, the famed Mauryan ruler King Ashoka established this city in 250 BC, which was then situated 5 kilometers from present-day Srinagar, as mentioned in Kalhan’s Rajatarangini.\n\n\n4.1.2 History of Planning Policies ?\nThroughout history, Srinagar has been on a journey of urban planning, dating back to before 1947. It began when Mr. W.G. Harris, a British Engineer, was enlisted by the State under Maharaja Gulab Singh’s rule after the devastating floods of 1902. His task was to devise a comprehensive flood management plan to ensure the sustainable development of the city. The first major planning initiative after Independence of India was the Srinagar Master Plan 1971-91. This plan spurred growth primarily towards the west and southwest, often encroaching upon low-lying areas, wetlands, and flood-prone zones near the Flood Spill Channel. However, the tumultuous period starting from 1989 resulted in a pause in planning efforts for about a decade. During this time, ineffective regulations by urban local bodies and authorities led to significant conversion of residential areas into commercial zones, further complicating the city’s development trajectory.\n\n\n4.1.3 Master Plan Srinagar-2035\nRecently devised Master Plan Srinagar-2035 was approved by the state government. The Master Plan-2035 is the third statutory planning exercise carried out for Srinagar city so far. However; the question remains as to how much has been achieved on ground vis-à-vis the master plan targets during the plan period of more than four decades. Certainly the progress is very dismal as evident on ground which is not surely not because of poor quality plans but due to absence of administrative zeal and lack of a strong political will. If we are to make our city economically more vibrant and environmentally sustainable, then there is no alternative to a sustained and long term planning vision as enshrined through master plans  (n.d.).\nThe Master Plan-2035 proposes:\n\nComprehensive land suitability analysis based on scientific parameters.\nComprehensive identification and mapping of heritage buildings/precincts for revitalization and social inclusion of core city Srinagar.\nPolicies for promotion of local craft and tourism on sustainable norms.\nFocus on policies connecting rural economy with urban economy.\nRestructuring of Srinagar city for its sustenance and improving index of urban living.\nUse of GIS technology for accuracy and data base creation.\nA unique Development Code based on individual zone system as per development intensity and natural setting aiming at promoting the development rather than constricting it.\nTDRs and Green FAR for heritage conservation and land value capturing or monetization of land.\n\n\n\n4.1.4 Analyzing Srinagar Master Plan Through the Lens of NUA and Sendai Framework\nThe Srinagar Master Plan 2035 is closely aligned with the New Urban Agenda (NUA) and the Sendai Framework for Disaster Risk Reduction at least in words, advocating for resilient and sustainable urban growth. It integrates strategic land use planning with a strong emphasis on preserving cultural and natural assets, mirroring the NUA’s vision for inclusive and sustainable urban environments. The plan’s focus on mitigating disaster risks also corresponds with the Sendai Framework’s objectives, seeking to fortify Srinagar against the adverse effects of climate change and natural disasters.\nKey aspects of the plan, including community development, housing, and urban design, aim to enhance the living standards in Srinagar, echoing the NUA’s pursuit of improved life quality and aligning with the Sendai Framework’s call for readiness and resilience.\nHowever, despite its alignment with these global frameworks, the plan’s effectiveness may be hindered by a lack of concrete implementation strategies and a path forward. The absence of a detailed operational framework, clear procedures, and mechanisms for action could potentially limit its impact, raising concerns that it might follow the fate of previous master plans without any tangible outcomes.\nSrinagar comes under Seismic Zone-5 and is Flood Prone and has suffered many floods with recent being the 2014 flood. So, a concrete urban master plan is required for this city surrounded by the Himalayas and the Pir Panjal mountain ranges."
  },
  {
    "objectID": "week_5.html#summary",
    "href": "week_5.html#summary",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week was for Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets.\n\nWhat is GEE?\n\nGEE is a cloud-based platform for processing large geospatial datasets.\nIt simplifies data access and analysis for researchers, policymakers, NGOs, and the public.\nGEE uses an API and web-based IDE for rapid prototyping and visualization.\nKey terminology includes objects (vectors, rasters, features), images (raster data), and geometries (points, lines, polygons).\n\nFunctionalities\n\nGEE facilitates spatial operations, machine learning tasks, and statistical analyses.\nIts functionalities include reducing imagery, accessing data from multiple sensors, and performing joins and intersections.\n\n\nLast year, shortly after arriving in London, one of my initial tasks was to explore the evolution of Canary Wharf from its roots as docks to its current status as a financial hub. I connected to the city a lot more after this exposure of the history. Let us look at the transformation of Canary Wharf from its origins as dockyards to becoming a bustling business district.You can witness this evolution through Google Timelapse “Google Timelapse” (n.d.), one of the products of GEE. Simply press play button to observe the journey through time"
  },
  {
    "objectID": "week_5.html#applications",
    "href": "week_5.html#applications",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nThere have been so advancment in remote sensing research and ease of doing research with satellite data because of GEE. So, I made a tree map of “What is the craze about GEE and which sectors has it impacted”.\n\n\n\nGEE the bridge that connects, Source - Author"
  },
  {
    "objectID": "week_5.html#reflections",
    "href": "week_5.html#reflections",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nGEE presents an intriguing tool for analysis, showcasing the impressive strides in technology and data analysis. Its ability to swiftly process vast amounts of data quickly as compared to tools like SNAP and R, make it exceptionally useful and futuristic. The versatility of GEE is evident in its extensive data access and diverse range of applications, spanning from straightforward to intricate processing tasks. I firmly believe that GEE and cloud computing will revolutionize remote sensing research. Despite my prior experience in Python and R, exploring a new coding language like JavaScript piques my interest, prompting me to consider further learning opportunities.But, again, this entire course of MSc Urban Spatial Science has been an opportunity to go to uncharted territories and moving away from your comfort zone. And despite the demanding nature of the course, this exploration has been immensely enriching, largely thanks to the outstanding faculty at CASA, whom I consider are among the finest at Bartlett.\n\n\n\n\n“Google Timelapse.” n.d. Accessed March 9, 2024. https://earthengine.google.com/timelapse/."
  },
  {
    "objectID": "week_3.html#applications",
    "href": "week_3.html#applications",
    "title": "3  Week 3 - Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nThis week’s session focused on rectifying raw satellite images, merging them, and enhancing their quality, particularly delving into the significance of atmospheric corrections in satellite image studies. It’s crucial to recognize that satellite images often suffer from distortions due to various factors which were discussed above, and these can compromise the accuracy of our analysis. To mitigate these distortions, the corrections are routinely applied as a prerequisite before conducting analysis. These corrections ensure that the images are properly aligned and scaled, laying a reliable groundwork for subsequent interpretation and extraction of meaningful data.\nI stumbled upon a research paper by Hassan et al. (2006), where they delve into examining how changes in the number of Ground Control Points (GCPs) and the degree of mapping polynomials affect the accuracy of the geometric correction process. They utilized the Root Mean Square Error (RMS) at the chosen GCPs to gauge the accuracy of their findings. The study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.\n\n\n\na & b – Shows the raw image2 and its corresponding reference image, c & d – 4 GCPs distribution on raw image2 and its reference, e & f – corrected image2, and its reference,Source:Hassan et al. (2006)\n\n\nSimilarly, the same image was corrected by using 16 Ground Control Points as shown below.\n\n\n\na & b – shows the raw image2 and its corresponding reference image, c & d – 16 GCPs distribution on raw image2 and its reference, e & f – corrected image2, and its reference, Source Hassan et al. (2006)\n\n\nThe study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.The results of the study with respect to GCP, RMS is shown below.\n\n\n\nAverage of RMS error of all test images at each order of polynomials, Source Hassan et al. (2006)"
  },
  {
    "objectID": "week_3.html#reflections",
    "href": "week_3.html#reflections",
    "title": "3  Week 3 - Corrections",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections\nAs I joined the Term quite late, so had to catch up with all in a short amount of time. But, as the lectures and the practical notebooks were crafted perfectly, so I was able to grasp most of the concepts. Regarding, this week, I understand the importance of covering corrections, despite their initial complexity, to ensure data quality and facilitate comparison between different images. Exploring how remotely sensed images can be manipulated reveals deeper layers of information beyond the surface data. Although I didn’t do the practical exercises this week, but I have gone through the code and have also checked the Ahmad (n.d.) as recommended & I found it valuable and I anticipate revisiting it in future.\n\n\n\n\nAhmad, Dr. Zia. n.d. “Geospatial Data Science in R.” Accessed March 9, 2024. https://zia207.github.io/geospatial-r-github.io/index.html.\n\n\nHassan, Fawzy, Gouda Salama, Esam Hamza, and H. Hussien. 2006. “GEOMETRIC CORRECTION OF REMOTE SENSING SATELLITE DIGITAL IMAGES USING MAPPING POLYNOMIAL OF DIFFERENT ORDERS.” The International Conference on Electrical Engineering 5 (5): 1–22. https://doi.org/10.21608/iceeng.2006.33672."
  },
  {
    "objectID": "week_3.html#summary",
    "href": "week_3.html#summary",
    "title": "3  Week 3 - Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\nRemotely sensed data requires corrections to remove flaws which may be due to various factors like - atmosphere, sensor sensitivity, illumination conditions, distortions due to viewing angle,topographic conditions,etc.\n- Atmospheric Correction: It removes flaws caused in the remotely sensed data due to atmosphere.The atmosphere affects the incoming sunlight thereby leading to reflection, scattering and absorption of various parts of electromagnetic spectrum. Atmospheric correction is either relative or absolute. Relative atmospheric correction adjusts the data based on radiance values of target area with respect to neighboring area, while as, in absolute atmospheric correction we convert digital brightness values into scaled surface reflectance. This allows us to directly compare these scaled surface reflectance values across different regions of the planet, facilitating accurate analysis and interpretation of Earth’s surface characteristics and changes over time.\n- Geometric Correction: Geometric correction involves adjusting remotely sensed data to account for image distortions introduced by various factors such as the view angle (off-nadir), topography (e.g., non-flat terrain), wind (in aerial acquisitions), and the rotation of the Earth (in satellite imagery). This correction ensures that the satellite image aligns accurately with a coordinate reference system.\n- Topographic Correction: It deals with the effect of terrain variations on reflectance values.It requires sensor geometry and elevation data. After incorporating it, the accuracy and consistency of remote sensing data improves across different terrain conditions.\n- Radiometric Correction: This correction accounts for sensor-related factors such as variations in sensor sensitivity, illumination conditions, and atmospheric effects, ensuring that the resulting data accurately represents the physical properties of the observed features."
  },
  {
    "objectID": "week_6.html#summary",
    "href": "week_6.html#summary",
    "title": "6  Week 6 - Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nClassification in remote sensing involves categorizing pixels in imagery to label them based on land cover use or other characteristics. This process is integral to various data processing pipelines and is commonly used for identifying urban areas, vegetation, and other land uses. This week’s lecture focused on classification in remote sensing and its implementation using machine learning techniques.Machine learning methods discussed include classification and regression trees (CART), random forests, maximum likelihood, and support vector machine (SVM). The lecture also covered supervised and unsupervised image classification approaches. Each classification method has its own principles and considerations, such as the need for human knowledge in expert systems, the use of decision rules in maximum likelihood classification, and the margin optimization in SVM. Considerations include whether to classify pixels or objects, the selection of the appropriate machine learning model, and the determination of necessary hyperparameters. Overall, this week’s lecture provided a comprehensive overview of classification methods in remote sensing and their application through machine learning."
  },
  {
    "objectID": "week_7.html#summary",
    "href": "week_7.html#summary",
    "title": "7  Week 7 - Classification I",
    "section": "7.1 Summary",
    "text": "7.1 Summary\nClassification in remote sensing is the process of sorting pixels in images to label them, which is essential for tasks such as monitoring urban green spaces or combating illegal logging in forests, and other land uses. This week’s lecture focused on classification in remote sensing and its implementation using machine learning techniques.Machine learning methods discussed include classification and regression trees (CART), random forests, maximum likelihood, and support vector machine (SVM). The lecture also covered supervised and unsupervised image classification approaches. Each classification method has its own principles and considerations, such as the need for human knowledge in expert systems, the use of decision rules in maximum likelihood classification, and the margin optimization in SVM. Considerations include whether to classify pixels or objects, the selection of the appropriate machine learning model, and the determination of necessary hyperparameters.\n\n7.1.1 Classification and Regression Trees (CART)?\n\nIt creates a hierarchical model composed of nodes and branches. Nodes signify decision points, while branches represent outcomes. At the end of the hierarchy, leaf nodes contain predicted values for the target variable.\nIt creates a hierarchical model composed of nodes and branches. Nodes signify decision points, while branches represent outcomes. At the end of the hierarchy, leaf nodes contain predicted values for the target variable.\n\nYAY’S\n\nClassification and regression trees implicitly perform feature selection.\nOutliers have no meaningful effect on CART.\nIt requires minimal supervision and produces easy-to-understand models.\n\nNAY’S\n\nOverfitting.\nHigh Variance.\nLow bias.\nStructure may be unstable.\n\n\n\n7.1.2 Random Forest?\n\nRandom forests use many decision trees together. Each tree is made from a different part of the data, and their predictions are combined to give a final answer. This helps overcome any mistakes from individual trees, making the overall result more accurate.\nRandom forests are better than single decision trees because they are more flexible, accurate, and easier to use. They’re great for both classifying things and predicting values, making them a top pick in machine learning. Basically, random forests make decision trees work better by teaming them up, resulting in better performance overall.\n\nYAY’S\n\nProvide high accuracy in both classification and regression tasks.\nRobust to overfitting\nSuitable for a wide range of tasks, including handling both numerical and categorical data.\n\nNAY’S\n\nRandom forests can be more complex to interpret\nTraining a random forest can be computationally expensive and require significant memory.\nOptimizing hyperparameters for random forests can be challenging and time-consuming.\nMay not perform well with very small datasets due to the risk of overfitting and limited diversity among trees."
  },
  {
    "objectID": "week_7.html#applications",
    "href": "week_7.html#applications",
    "title": "7  Week 7 - Classification I",
    "section": "7.2 Applications",
    "text": "7.2 Applications\nFor this week, I explored the used of Classification and Regression Trees (CART) and Random forests (RF) using Google Earth Engine. Here are my results for both CART & RF Classification, after using the Sentinel-2 Data provided by GEE and applying it to Srinagar City. For, this exercise I identified three types of landcovers - water, urban and forest. Further, I filtered the data for the year 2020 and limited the satellite images with less than 20% cloud cover and then obtained a composite image by using the median function.\n\nCART Classification:\n\n\n\n\nCART Classification of Srinagar City for the year 2020 - Work: Author’s Own , Used: Sentinel-2 MSI: MultiSpectral Instrument, Level-1C “User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online” (n.d.)\n\n\n\nRF Classification:\n\n\n\n\nRandom Forest Classification of Srinagar City for the year 2020 - Work: Author’s Own , Used: Sentinel-2 MSI: MultiSpectral Instrument, Level-1C “User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online” (n.d.)\n\n\n\nDifference between CART & RF\n\nAfter this to get a holistic view of the difference between the two, I obtained the difference layer and it could be seen in the difference image that Random Forest wrongly identified the central part of Dal Lake as Forest while as Classification and Regression Trees (CART) did a good job there as it identified it as water. In this “Black” denotes the similar classification by CART and RF while as “Yellow” denoted mismatch between the two.\n\n\n\nDifference CART vs RF Classification of Srinagar City for the year 2020 - Work: Author’s Own , Used: Sentinel-2 MSI: MultiSpectral Instrument, Level-1C “User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online” (n.d.)"
  },
  {
    "objectID": "week_7.html#reflections",
    "href": "week_7.html#reflections",
    "title": "7  Week 7 - Classification I",
    "section": "7.3 Reflections",
    "text": "7.3 Reflections\nThis week was a lot of important topics and it explored the intricacies of machine learning for informed decision-making, even if the technical details are difficult to grasp. I will be revising this lecture and will be using these techniques in Google Earth Engine in near future. While doing the Classification analysis, I was able to obatin an interesting thing. I compared the CART Classification of Srinagar City for the year 2015 and for the year 2020 and I was able to deduce the following:-\n\nThere have been massive campaigns in the city to protect the Dal Lake (also called the “Srinagar’s Jewel” ) and it could be seen in the area designated as “A” in the image below that in 2015, a portion of the lake has been identified as a vegetation/forest by our model indicating pollution in the lake while the same patch is shown as water in 2020, so clearly indicating that the efforts by the state government to clean the lake have somewhat succeeded.\nAlso, it is also to be noted that in the area designated as “B” there has been lost of forest cover and increase in the urban cover, indicating the urban expansion of city from the north-west side.\n\n\n\n\nChanges in landcover from 2015 to 2020 for Srinagar City - Work: Author’s Own , Used: Sentinel-2 MSI: MultiSpectral Instrument, Level-1C “User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online” (n.d.)\n\n\n\n\n\n\n“User Guides - Sentinel-2 MSI - Level-1 Processing - Sentinel Online.” n.d. Sentinel Online. Accessed March 17, 2024. https://copernicus.eu/user-guides/sentinel-2-msi/processing-levels/level-1."
  },
  {
    "objectID": "week_8.html#summary",
    "href": "week_8.html#summary",
    "title": "8  Week 8 - Classification II",
    "section": "8.1 Summary",
    "text": "8.1 Summary\nThis week’s focus remained on exploring additional classification methods with particular attention given to object-based image analysis and sub-pixel analysis. Below, I will explore these in details below.\n\n8.1.1 Object Based Image Analysis (OBIA)\nIn contrast to pixel-based classification methods that classify individual pixels directly, object-based classification first aggregates image pixels into spectrally homo-genous image objects using an image segmentation algorithm which clusters pixels based on spatial proximity and colour similarity and resulting in classification of individual objects (Liu and Xia (2010)).\n\n\n8.1.2 Sub-Pixel Analysis\nSub-pixel analysis examines the contents of a single pixel, determining the mix of land cover types within it. It calculates the percentage of each land cover type per pixel by comparing reflectance values.This method helps classify pixels, particularly when they contain multiple land cover types. It estimates the portion of each pixel covered by different materials. Unlike multi-pixel analysis, sub-pixel analysis concentrates on individual pixels, essential for satellite images with low resolution where each pixel covers a larger land area.\nThe study by Whiteside, Boggs, and Maier (2011) explains the object-based & pixel type of analysis.In the pixel-based classification, each pixel is classified separately, whereas in the object-based classification, all pixels that belong to one GIS object are grouped together. The result of the pixel grouping is like a smoothing of the data. Resultant noise in the pixel-based classification shows why OBIA has great advantage over it.\n\n\n\nLST Values for different years,of Indianapolis, USA. Source - Whiteside, Boggs, and Maier (2011)\n\n\n\n\n8.1.3 Accuracy\nIn remote sensing and machine learning, we use different methods to check how accurate our models are. The one we pick depends on what we’re using the model for. Some common ones are user’s accuracy, producer’s accuracy, and F1 score which we obtain from confusion matrix - which is a table showing how many pixels were classified correctly or incorrectly for each class. Here is a brief overview of all these parameters\n\n\n\n\n\n\n\n\n\n\n\nProducer’s Accuracy\nUser’s Accuracy\nOverall Accuracy\nKappa Coefficient\n\n\n\n\nExplanation\nMeasures the proportion of actual positive cases that were correctly identified positive cases.\nMeasures the proportion of correctly identified positive cases out of all cases classified as positive.\nMeasures the proportion of all correctly classified pixels out of all observations.\nMeasures the agreement between observed and expected accuracy levels when there is no agreement by chance.\n\n\nFormula\n\\(\\frac{TP}{TP+FN}\\)\n\\(\\frac{TP}{TP+FP}\\)\n\\(\\frac{TP+TN}{TP+FP+TN+FN}\\)\n\\(\\frac{p_o-p_e}{1-p_e}\\)"
  },
  {
    "objectID": "week_8.html#applications",
    "href": "week_8.html#applications",
    "title": "8  Week 8 - Classification II",
    "section": "8.2 Applications",
    "text": "8.2 Applications\nOne of the studies that came across while reading about Sub-Pixel Analyis was of Weng and Lu (2008) in which they studied the urbanization effect on land surface temperature (LST) in USA. In this study they gathered the satellite images from different time intervals (in years) and they analyzed the rise in urbanization with the land surface temperature. The study demonstrated that Urbanization created an evolved inverse relationship between impervious and vegetation coverage, and brought about new LST patterns because of LST’s correlations with both impervious and vegetation coverage.\n\n\n\nLST Values for different years,of Indianapolis, USA. Source - Weng and Lu (2008)\n\n\nAlso, one of the application of Object-based image analysis came across during my reading was the study done by Najafi et al. (2018) in Iran to determine the crop residue estimate using Landsat data by applying the OBIA. To process the data, they applied the object-based image processing steps which include segmentation and classification and developed intelligent objects. Further, after applying OBIA algorithms results were validated against ground control data set by field survey.\n\n\n\nClassification results of tillage indices functions: a to f. Source - Najafi et al. (2018)"
  },
  {
    "objectID": "week_8.html#reflections",
    "href": "week_8.html#reflections",
    "title": "8  Week 8 - Classification II",
    "section": "8.3 Reflections",
    "text": "8.3 Reflections\nThis week touched on the disparity between real-world features and satellite data, underscoring the importance of employing classification methods such as subpixel and object-based approaches to accurately interpret the data. Additionally, it’s crucial to refrain from depending solely on commonly used metrics without verifying their validity. We need to assess whether the coefficients we utilize are suitable for the specific task at hand. Also, the impact of spatial autocorrelation in classification systems offers a fresh perspective, particularly when dealing with other spatial data. Reflecting on all of this, I feel content and pleased to know the practical applications of remote sensing data, particularly in urban environments.\n\n\n\n\nLiu, Desheng, and Fan Xia. 2010. “Assessing Object-Based Classification: Advantages and Limitations.” Remote Sensing Letters 1 (4): 187–94. https://doi.org/10.1080/01431161003743173.\n\n\nNajafi, P., H. Navid, B. Feizizadeh, and I. Eskandari. 2018. “Object-Based Satellite Image Analysis Applied for Crop Residue Estimating Using Landsat OLI Imagery.” International Journal of Remote Sensing 39 (19): 6117–36. https://doi.org/10.1080/01431161.2018.1454621.\n\n\nWeng, Qihao, and Dengsheng Lu. 2008. “A Sub-Pixel Analysis of Urbanization Effect on Land Surface Temperature and Its Interplay with Impervious Surface and Vegetation Coverage in Indianapolis, United States.” International Journal of Applied Earth Observation and Geoinformation 10 (1): 68–83. https://doi.org/10.1016/j.jag.2007.05.002.\n\n\nWhiteside, Timothy G., Guy S. Boggs, and Stefan W. Maier. 2011. “Comparing Object-Based and Pixel-Based Classifications for Mapping Savannas.” International Journal of Applied Earth Observation and Geoinformation 13 (6): 884–93. https://doi.org/10.1016/j.jag.2011.06.008."
  },
  {
    "objectID": "week_9.html#summary",
    "href": "week_9.html#summary",
    "title": "9  Week 9 - SAR",
    "section": "9.1 Summary",
    "text": "9.1 Summary\n\n9.1.1 SAR:\nWhat is the fuss about Synthethic Aperture Radar aka SAR. Let us know some facts about SAR:-\n\nSynthetic Aperture RADAR (SAR) became a well-established and powerful remote sensing technology used worldwide for several applications thanks to the possibility of sensing the Earth’s surface at night and day, and in any weather condition Synthetic Aperture Radar (SAR) Techniques and Applications (2020).\nSynthetic Aperture Radar (SAR) is a form of active data collection (Earth Science Data Systems (2020)).\nSAR sensors generate their own energy and measure the amount of energy reflected back from the Earth’s surface.\nUnlike optical imagery, which is akin to interpreting a photograph, SAR data interpretation requires a different approach. The process will use multiple pulsed electromagnetic frequencies with different wavelengths in combinations to build up images of the target survey area. The different frequencies can have the ability to penetrate vegetation/canopy and even soils (“Synthetic Aperture Radar” (n.d.)).\nSAR signals are responsive to surface characteristics such as structure and moisture rather than visual appearance.\nSAR data can be used for various applications including agriculture, forestry, urban planning, disaster monitoring, and military surveillance.\nSAR technology has both civilian and military applications, with satellites and aircraft being common platforms & now drones as well contribute to the SAR data collection.\nSAR data can provide valuable insights into changes in the Earth’s surface over time, aiding in environmental monitoring and resource management.\n\n\n\n\nSAR with different wavelengths, Source:“Synthetic Aperture Radar” (n.d.)\n\n\nOne of the early uses of SAR over the Optical can be seen in the figure below & it is one of the early SAR images. This was taken by astronauts onboard the space shuttle endeavor on Sept 30, 1994.The image on left is a optical image & the right is a radar image which shows the flow of lava and it penetrates the dark ash & smoke coming from erupting lava, thus giving us the view of the erupting volcano.\n\n\n\nOptical vs SAR, Kamchatka Volcano, Russia. Source:“SIR-C/X-SAR Image Kliuchevskoi Volcano Comparison” (n.d.)"
  },
  {
    "objectID": "week_9.html#applications",
    "href": "week_9.html#applications",
    "title": "9  Week 9 - SAR",
    "section": "9.2 Applications",
    "text": "9.2 Applications\nSAR has been used for many application like land cover changes, deforestation, for monitoring disaster episodes (floods, earthquakes, landslides,etc), for monitoring crop yield, for monitoring glaciers & in human aid. One of the research which came across during my readings was Flood & damage mapping in Japan by Tay et al. (2020) . in this study they used SAR for deriving at a flood map using change detection approach.The validation was carried by aerial imagery & other optical sources.\n\n\n\nFlood Extent - The blue polygon indicates the SAR footprint and white rectangles indicate the extents of zoomed-in panels on the right. Source:Tay et al. (2020)\n\n\nAnother application of SAR, that was quite interesting to me because of my Civil Engineering background, was the use of SAR in monitoring Transport Infrastructure Edward J Hoppe et al. (2016). In this the researchers selected the COSMO-SkyMed satellite system operated by the Italian Space Agency & it provides a coverage of 3-m pixel resolution when operated in “HIMAGE” mode, effectively providing time-displacement data at the centroids of consecutive 3 × 3 m2 areas on the Earth’s surface.\n\n\n\nRoad with Good Patches & Bad Patches - Source:Edward J Hoppe et al. (2016)\n\n\nSatellite-based radar systems are now capable of detecting surface deformation in the order of a few millimeters, due to a technique known as interferometric synthetic aperture radar (InSAR), which has become a standard tool for the remote sensing of displacements.In this study they use InSAR technology to be able to detect sinkholes near the road infrastructure, movements around road embankments, potholes & pavement distress.\n\n\n\nRoad Infrastructure Monitoring - Source:Edward J Hoppe et al. (2016)"
  },
  {
    "objectID": "week_9.html#reflections",
    "href": "week_9.html#reflections",
    "title": "9  Week 9 - SAR",
    "section": "9.3 Reflections",
    "text": "9.3 Reflections\nI have been quite facinated by this lecture and I must say, the breadth of applications that SAR Technology offers is truly impressive. The sheer potential it holds across diverse fields is both inspiring and humbling.. I’m planning to use SAR for my Crop Yield Prediction project and will continue to explore its uses and applications.\nAt the end, I really feel happy and content with the work that I have done through this learning diary despite the time I had lost through a family emergency. But, I would like to congratulate Dr Andrew MacLachlan for structuring the course so well and for this unique way of assessment. It’s been satisfying, interesting, and I’ve learned a lot. Thanks, Andy.\n\n\n\n\nEarth Science Data Systems, NASA. 2020. “What Is Synthetic Aperture Radar? | Earthdata.” Backgrounder. Earth Science Data Systems, NASA. April 10, 2020. https://www.earthdata.nasa.gov/learn/backgrounders/what-is-sar.\n\n\nEdward J Hoppe, Brian Bruckno, Elizabeth Campbell, Scott T Acton, Andrea Vaccari, Michael Stuecheli, Adrian Bohane, Giacomo Falorni, and Jessica Morgan. 2016. “Transportation Infrastructure Monitoring Using Satellite Remote Sensing.” In Materials and Infrastructures 1. John Wiley & Sons, Inc. https://doi.org/10.1002/9781119318583.ch14.\n\n\n“SIR-C/X-SAR Image Kliuchevskoi Volcano Comparison.” n.d. Accessed March 15, 2024. https://www.geo.mtu.edu/volcanoes/klyuchevskoi/images/kliuch-compare.html.\n\n\n“Synthetic Aperture Radar.” n.d. Accessed March 15, 2024. https://www.surveyar.co.uk/fs08-radar-sar.\n\n\nSynthetic Aperture Radar (SAR) Techniques and Applications. 2020. MDPI. https://doi.org/10.3390/books978-3-03936-123-6.\n\n\nTay, Cheryl W. J., Sang-Ho Yun, Shi Tong Chin, Alok Bhardwaj, Jungkyo Jung, and Emma M. Hill. 2020. “Rapid Flood and Damage Mapping Using Synthetic Aperture Radar in Response to Typhoon Hagibis, Japan.” Scientific Data 7 (1): 100. https://doi.org/10.1038/s41597-020-0443-5."
  },
  {
    "objectID": "week_4.html#introduction",
    "href": "week_4.html#introduction",
    "title": "4  Week 4 - Policy",
    "section": "4.2 Introduction",
    "text": "4.2 Introduction\nFor this week’s challenge, I choose the city where I grew up in viz. Srinagar. Srinagar is the capital of Jammu and Kashmir, a state in northern India. Srinagar’s predicted population in 2024 is roughly 1.7 million (according to UN World Urbanization Prospects). It’s also worth noting that the Srinagar Metropolitan Region accounts for more than 75% of the urban population, indicating highly unbalanced urbanisation or macrocephaly. Before we go any further, let me provide a brief historical overview of the city. Srinagar’s name has been linked with some of its most known historical stories. The words “Sri” mean “Goddess of Wealth” and “nagar” imply “city”. As a result, the city is famously known as the “City of Wealth”.Today, Srinagar stands as one of the world’s most coveted tourist destinations, yet it has a history that has shaped it into what it is now. According to certain renowned historians, the famed Mauryan ruler King Ashoka established this city in 250 BC, which was then situated 5 kilometers from present-day Srinagar, as mentioned in Kalhan’s Rajatarangini."
  },
  {
    "objectID": "week_4.html#applications",
    "href": "week_4.html#applications",
    "title": "4  Week 4 - Policy",
    "section": "4.2 Applications",
    "text": "4.2 Applications\nTo address the gaps in the Srinagar Master Plan 2035, particularly in comparison to the New Urban Agenda (NUA) and the Sendai Framework, leveraging remote sensing and Google Earth Engine (GEE) offers innovative and powerful approaches. These technologies can enhance urban planning and disaster risk reduction efforts through detailed and up-to-date geographic information. Here’s how they can be applied to address the identified lacunas:\n\nUrban Expansion and Land Use Planning: We can apply GEE’s satellite imagery database to monitor urban sprawl and land use changes over time, integrating this data with urban planning tools to guide sustainable development.Apart from that the interactive panel structure of GEE makes it easy to show the policy makers its application. A similar approach was used by Patel et al. (2015) for the automated extraction of urban areas from Landsat imagery using GEE.\nDisaster Risk Reduction and Management We can use remote sensing and GEE for modeling flood scenarios and mapping hazard-prone areas to inform infrastructure resilience strategies.A similar approach was proposed for Bangladesh by Franci, Mandanici, and Bitelli (2015). We could leverage the remote sensing to identify the area which are getting most affected.And, implement polices like no residential construction in these regions,increase the land tax in these neighbourhoods for preventing people from buying land there so thus decrease the construction activities, and thus indirectly less disaster response required in the eventuality of a disaster.\n\n Likewise, following the identification of heritage sites/buildings, establishing a buffer zone can serve as a measure to halt encroachment and impose stricter building regulations within this zone, thereby safeguarding the integrity of Kashmir’s age-old heritage. When contemplating heritage preservation, London’s blue plaques come to my mind as a notable example (“Blue Plaques | London City Hall” (n.d.)). It is my hope that Kashmir can introduce its own version of blue plaques, offering a window into its profound history and becoming a symbol of pride and achievement."
  },
  {
    "objectID": "week_4.html#reflections",
    "href": "week_4.html#reflections",
    "title": "4  Week 4 - Policy",
    "section": "4.3 Reflections",
    "text": "4.3 Reflections\nUpon reflecting on the policy-making process, I’ve come to believe that possessing a strong communication style is crucial, potentially even more so than having technical expertise. My experience as a public servant in India, where I’ve been directly involved in implementing policies, has taught me the significant challenge of bringing together various stakeholders to find common ground. It demands considerable courage and diplomacy. So, for best outcome of a policy, it should be supported by a good technical and scientific approach, & then the face of the policy should be a great saleman who can sell your vision. And in my view, the Masterplan of Srinagar 2035 lacked both and if in future I become a part of the policy making team, which I am sure I might; I will keep all this in mind.\n\n\n\n\nn.d. Srinagar Master Plan 2035. Accessed March 17, 2024. https://sdasrinagar.jk.gov.in/planning/MasterPlan.\n\n\n“Blue Plaques | London City Hall.” n.d. Accessed March 17, 2024. https://www.london.gov.uk/who-we-are/what-london-assembly-does/questions-mayor/find-an-answer/blue-plaques.\n\n\nFranci, Francesca, Emanuele Mandanici, and Gabriele Bitelli. 2015. “Remote Sensing Analysis for Flood Risk Management in Urban Sprawl Contexts.” Geomatics, Natural Hazards and Risk 6 (5-7): 583–99. https://doi.org/10.1080/19475705.2014.913695.\n\n\nPatel, Nirav N., Emanuele Angiuli, Paolo Gamba, Andrea Gaughan, Gianni Lisini, Forrest R. Stevens, Andrew J. Tatem, and Giovanna Trianni. 2015. “Multitemporal Settlement and Population Mapping from Landsat Using Google Earth Engine.” International Journal of Applied Earth Observation and Geoinformation 35 (March): 199–208. https://doi.org/10.1016/j.jag.2014.09.005."
  }
]