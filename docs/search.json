[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome to Remote Sensing",
    "section": "",
    "text": "Welcome\nI am Burhan. Born and brought up in the beautiful valley of Kashmir.Yeah, we are famous for Beautiful Valleys, Mesmerizing Lakes, Cashmere Shawls & Wazwan (our local cuisine). Take a glimpse of my hometown through this elaborate Photo Gallery or the one short one below.\n\n\n\n\nI am a Passionate Urban Spatial Enthusiast pursuing postgraduate studies at University College London (UCL), blending expertise in Urban Spatial Sciences and Civil Engineering.I have held mid-level management positions in both government and the public sector, specializing in the strategic development of road networks for underserved areas in India. My mojo revolves around crafting the future of transportation design, playing with spatial analytics, rocking disaster management scenarios, championing net-zero strategies, and setting the stage for cool public policies. Committed to driving positive change, seeking collaboration with like-minded professionals to shape a more sustainable future for cities and regions.\n\n \n\nGratitude: As I was away from first five weeks, so had to catch up to a lot in a small amount of time. But, I would like to express my gratitude to the my department (in general) and Dr Andrew MacLachlan (in particular) for guiding me through this and I hope I have managed to produce a good learning diary and met the expectations of my peers."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee (knuth84?) for additional discussion of literate programming.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Ahmad, Dr. Zia. n.d. “Geospatial Data Science in\nR.” Accessed March 9, 2024. https://zia207.github.io/geospatial-r-github.io/index.html.\n\n\nDarbari, Priyanka, and Manoj Kumar. 2022. “Satellite Image\nEnhancement Techniques: A Comprehensive\nReview.” In Proceedings of International\nConference on Communication and Artificial\nIntelligence, edited by Vishal Goyal, Manish Gupta, Seyedali\nMirjalili, and Aditya Trivedi, 431–47. Lecture Notes in\nNetworks and Systems. Singapore: Springer\nNature. https://doi.org/10.1007/978-981-19-0976-4_36.\n\n\nEarthdata-Website. 2019. “What Is Remote Sensing? |\nEarthdata.” Backgrounder. Earth Science Data\nSystems, NASA. August 23, 2019. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n\n\nElachi, Charles, and van Zyl Jakob J. 2006. “Introduction to the\nPhysics and Techniques of Remote\nSensing.” In Introduction to the Physics and\nTechniques of Remote Sensing, 1–21. Hoboken, NJ, USA: John Wiley\n& Sons, Inc.\n\n\nGIPHY, dir. n.d. Space Satellite GIF by\nNASA - Find & Share on\nGIPHY. Accessed February 4, 2024. https://giphy.com/gifs/nasa-space-nasagif-3ohc0PkM8mVYfmBHz2.\n\n\nHassan, Fawzy, Gouda Salama, Esam Hamza, and H. Hussien. 2006.\n“GEOMETRIC CORRECTION OF REMOTE SENSING SATELLITE DIGITAL\nIMAGES USING MAPPING POLYNOMIAL OF DIFFERENT ORDERS.”\nThe International Conference on Electrical Engineering 5 (5):\n1–22. https://doi.org/10.21608/iceeng.2006.33672.\n\n\nMishra, Anoop Kumar. 2015. “A Study on the Occurrence of Flood\nEvents over Jammu and Kashmir During\nSeptember 2014 Using Satellite Remote Sensing.”\nNatural Hazards 78 (2): 1463–67. https://doi.org/10.1007/s11069-015-1768-9.\n\n\n“Remote Sensing By Satellite: Physical\nBasis, Principles, & Uses.”\n2023. April 7, 2023. https://eos.com/blog/remote-sensing/.\n\n\n“The Nature Conservancy.” n.d. Accessed\nFebruary 4, 2024. https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/."
  },
  {
    "objectID": "week_1.html",
    "href": "week_1.html",
    "title": "1  Week 1 - Basics",
    "section": "",
    "text": "2 Summary\nRemote sensing data finds numerous applications across diverse fields. It is used in agriculture for optimizing uses of fertilizers, prediction of crop yields,measuring soil moisture content, monitoring droughts, assessment of crop health, etc.\nSimilarly, in forestry it can be used for monitoring forest cover, tracking deforestation & controlling forest fires.Also, remote sensing is being used for checking the rapid urbanization, planning road networks, pre and post disaster preparedness & in many more fields.\nAlso, during my research regarding the use of remote sensing, I came across one of the works which discussed the application of remote sensing in route planning for road projects in challenging terrain (Mishra (2015)). This study delved into the effectiveness of remote sensing and Geographic Information Systems (GIS) in mapping road infrastructure in rugged landscapes. Various factors influencing road network construction and the resolution of associated challenges were examined within a specific context. Criteria encompassing major and subsidiary factors were assessed to select an appropriate model for comparing attributes and grading them based on their significance. All these examples together demonstrate how valuable remote sensing technology is across a wide range of fields.\nTransitioning from a Civil Engineering background to the realm of spatial science, particularly remote sensing, has been a thrilling journey. One notable application that resonates with me, especially concerning India, is the utilization of remote sensing for identifying “Unconnected Habitations.” These are isolated dwellings or small clusters of houses situated in regions lacking road access, electricity, and water supply. Typically nestled in mountainous terrains, these areas are predominantly inhabited by tribal communities. So, by leveraging remote sensing technology we could identify these remote settlements, facilitating the formulation of targeted policies aimed at fostering development within these underserved regions."
  },
  {
    "objectID": "week_1.html#what-is-remote-sensing-you-ask",
    "href": "week_1.html#what-is-remote-sensing-you-ask",
    "title": "1  Week 1 - Basics",
    "section": "2.1 What is Remote Sensing, you ask?",
    "text": "2.1 What is Remote Sensing, you ask?\nRemote sensing is like Earth’s Personal Observer, capturing information from afar. NASA defines Remote Sensing as acquiring information from a distance - Earthdata-Website (2019) . Also, Elachi and van Zyl (2006) define remote sensing as “the acquisition of information about an object without being in physical contact with it”. All this is achieved through sensors mounted on satellites, planes, drones, etc.\n\n\n\nSpace Satellite GIF by NASA - GIPHY (n.d.)"
  },
  {
    "objectID": "week_1.html#types-of-sensors",
    "href": "week_1.html#types-of-sensors",
    "title": "1  Week 1 - Basics",
    "section": "2.2 Types of Sensors ?",
    "text": "2.2 Types of Sensors ?\nRemote sensing employs two main types of sensors: Passive and Active.\nPassive sensors rely on sunlight reflected off the Earth’s surface. However, they are susceptible to interference from elements like clouds and atmospheric haze.\nActive sensors, on the other hand, emit signals directed towards the Earth, which bounce back to the satellite sensor. This allows active sensors to operate effectively at night and even penetrate through cloud cover, enhancing their versatility.\nThe choice between passive and active sensors depends on the specific environmental conditions and the type of data required for remote sensing applications. A basic difference of the two is shown in the below image explicitly\n\n\n\nDifference between passive and active sensors for remote sensing. Image © “The Nature Conservancy” (n.d.)"
  },
  {
    "objectID": "week_1.html#electromagnetic-spectrum",
    "href": "week_1.html#electromagnetic-spectrum",
    "title": "1  Week 1 - Basics",
    "section": "2.3 Electromagnetic Spectrum ?",
    "text": "2.3 Electromagnetic Spectrum ?\nRemote sensing is based on the principle that there is always an interaction between electromagnetic radiation and an object.Electromagnetic waves travel through the air and space, each with different wavelengths and frequencies. Some waves, like radio and infrared, have long wavelengths, while others, such as ultraviolet and x-rays, have short wavelength. Human eyes can only see a small part called visible light.\nDifferent types of radiation operate in various parts of the electromagnetic spectrum. Sensors can read different wavelengths, thus providing diverse information. Earth’s atmosphere blocks most wavelengths, allowing only radio waves, visible light, and some infrared. Instruments, like passive sensors in the optical window and active sensors using radio waves, help us understand our surroundings.\n\n\n\nElectromagnetic Spectrum, Source Earthdata-Website (2019)"
  },
  {
    "objectID": "week_1.html#resolutions",
    "href": "week_1.html#resolutions",
    "title": "1  Week 1 - Basics",
    "section": "2.4 Resolutions",
    "text": "2.4 Resolutions\nRemote sensing data encompasses four key resolutions:\n\nSpectral Resolution: It refers to the size of each raster cell or pixel, dictating the level of detail captured.\nSpatial Resolution: It defines defines the sensor’s capability to differentiate wavelengths, determining the number of bands recorded, with multispectral sensors typically capturing 3-15 bands and hyperspectral sensors capable of thousands.\nTemporal Resolution:It indicates the frequency at which an area is revisited, influencing the timeliness of data acquisition.\nRadiometric Resolution: It quantifies the information contained within each raster cell, with higher resolutions yielding greater sensitivity to variations.\n\n\n\n\nDiagram showing different Resolutions, Source Darbari and Kumar (2022)"
  },
  {
    "objectID": "week_3.html",
    "href": "week_3.html",
    "title": "3  Week 3 - Corrections",
    "section": "",
    "text": "4 Summary\nThis week’s session focused on rectifying raw satellite images, merging them, and enhancing their quality, particularly delving into the significance of atmospheric corrections in satellite image studies. It’s crucial to recognize that satellite images often suffer from distortions due to various factors which were discussed above, and these can compromise the accuracy of our analysis. To mitigate these distortions, the corrections are routinely applied as a prerequisite before conducting analysis. These corrections ensure that the images are properly aligned and scaled, laying a reliable groundwork for subsequent interpretation and extraction of meaningful data.\nI stumbled upon a research paper by Hassan et al. (2006), where they delve into examining how changes in the number of Ground Control Points (GCPs) and the degree of mapping polynomials affect the accuracy of the geometric correction process. They utilized the Root Mean Square Error (RMS) at the chosen GCPs to gauge the accuracy of their findings. The study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.\nSimilarly, the same image was corrected by using 16 Ground Control Points as shown below.\nThe study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.The results of the study with respect to GCP, RMS is shown below.\nAs I joined the Term quite late, so had to catch up with all in a short amount of time. But, as the lectures and the practical notebooks were crafted perfectly, so I was able to grasp most of the concepts. Regarding, this week, I understand the importance of covering corrections, despite their initial complexity, to ensure data quality and facilitate comparison between different images. Exploring how remotely sensed images can be manipulated reveals deeper layers of information beyond the surface data. Although I didn’t do the practical exercises this week, but I have gone through the code and have also checked the Ahmad (n.d.) as recommended & I found it valuable and I anticipate revisiting it in future."
  },
  {
    "objectID": "week_3.html#corrections",
    "href": "week_3.html#corrections",
    "title": "3  Week 3 - Corrections",
    "section": "4.1 Corrections",
    "text": "4.1 Corrections\nRemotely sensed data requires corrections to remove flaws which may be due to various factors like - atmosphere, sensor sensitivity, illumination conditions, distortions due to viewing angle,topographic conditions,etc.\n- Atmospheric Correction: It removes flaws caused in the remotely sensed data due to atmosphere.The atmosphere affects the incoming sunlight thereby leading to reflection, scattering and absorption of various parts of electromagnetic spectrum. Atmospheric correction is either relative or absolute. Relative atmospheric correction adjusts the data based on radiance values of target area with respect to neighboring area, while as, in absolute atmospheric correction we convert digital brightness values into scaled surface reflectance. This allows us to directly compare these scaled surface reflectance values across different regions of the planet, facilitating accurate analysis and interpretation of Earth’s surface characteristics and changes over time.\n- Geometric Correction: Geometric correction involves adjusting remotely sensed data to account for image distortions introduced by various factors such as the view angle (off-nadir), topography (e.g., non-flat terrain), wind (in aerial acquisitions), and the rotation of the Earth (in satellite imagery). This correction ensures that the satellite image aligns accurately with a coordinate reference system.\n- Topographic Correction: It deals with the effect of terrain variations on reflectance values.It requires sensor geometry and elevation data. After incorporating it, the accuracy and consistency of remote sensing data improves across different terrain conditions.\n- Radiometric Correction: This correction accounts for sensor-related factors such as variations in sensor sensitivity, illumination conditions, and atmospheric effects, ensuring that the resulting data accurately represents the physical properties of the observed features."
  },
  {
    "objectID": "week_5.html",
    "href": "week_5.html",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "",
    "text": "6 Summary\nThis week was for Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets.\n\nWhat is GEE?\n\nGEE is a cloud-based platform for processing large geospatial datasets.\nIt simplifies data access and analysis for researchers, policymakers, NGOs, and the public.\nGEE uses an API and web-based IDE for rapid prototyping and visualization.\nKey terminology includes objects (vectors, rasters, features), images (raster data), and geometries (points, lines, polygons).\n\nFunctionalities\n\nGEE facilitates spatial operations, machine learning tasks, and statistical analyses.\nIts functionalities include reducing imagery, accessing data from multiple sensors, and performing joins and intersections.\n\n\nLast year, shortly after arriving in London, one of my initial tasks was to explore the evolution of Canary Wharf from its roots as docks to its current status as a financial hub. I connected to the city a lot more after this exposure of the history. Let us look at the transformation of Canary Wharf from its origins as dockyards to becoming a bustling business district.You can witness this evolution through Google Timelapse “Google Timelapse” (n.d.), one of the products of GEE. Simply press play button to observe the journey through time\n\n\n\n\n7 Applications\nThere have been so advancment in remote sensing research and ease of doing research with satellite data because of GEE. So, I made a tree map of “What is the craze about GEE and which sectors has it impacted”.\n\n\n\nGEE the bridge that connects, Source - Author\n\n\n\n\n8 Reflections\nGEE presents an intriguing tool for analysis, showcasing the impressive strides in technology and data analysis. Its ability to swiftly process vast amounts of data quickly as compared to tools like SNAP and R, make it exceptionally useful and futuristic. The versatility of GEE is evident in its extensive data access and diverse range of applications, spanning from straightforward to intricate processing tasks. I firmly believe that GEE and cloud computing will revolutionize remote sensing research. Despite my prior experience in Python and R, exploring a new coding language like JavaScript piques my interest, prompting me to consider further learning opportunities.But, again, this entire course of MSc Urban Spatial Science has been an opportunity to go to uncharted territories and moving away from your comfort zone. And despite the demanding nature of the course, this exploration has been immensely enriching, largely thanks to the outstanding faculty at CASA, whom I consider are among the finest at Bartlett.\n\n\n\n\n“Google Timelapse.” n.d. Accessed March 9, 2024. https://earthengine.google.com/timelapse/."
  },
  {
    "objectID": "week_2.html",
    "href": "week_2.html",
    "title": "2  Week 2 - Sensor Presentation",
    "section": "",
    "text": "Burhan"
  },
  {
    "objectID": "week_4.html",
    "href": "week_4.html",
    "title": "4  Week 4 - Policy",
    "section": "",
    "text": "5 Summary\nThis week, we delved into Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets. GEE simplifies high-performance computing for researchers, facilitating sharing of results with various stakeholders. It offers an API and web-based IDE for quick prototyping and visualization. Instead of downloading heavy satellite imagery, GEE can swiftly load datasets, including various types of satellite imagery, via its Data Catalog. GEE operates on client-side code execution, enhancing speed, and utilizes JavaScript. It distinguishes between raster data (images) and vector data (features), organizing them into Image Collections and Feature Collections, respectively."
  },
  {
    "objectID": "week_6.html",
    "href": "week_6.html",
    "title": "6  Week 6 - Classification",
    "section": "",
    "text": "7 Summary\nClassification in remote sensing involves categorizing pixels in imagery to label them based on land cover use or other characteristics. This process is integral to various data processing pipelines and is commonly used for identifying urban areas, vegetation, and other land uses. This week’s lecture focused on classification in remote sensing and its implementation using machine learning techniques.Machine learning methods discussed include classification and regression trees (CART), random forests, maximum likelihood, and support vector machine (SVM). The lecture also covered supervised and unsupervised image classification approaches. Each classification method has its own principles and considerations, such as the need for human knowledge in expert systems, the use of decision rules in maximum likelihood classification, and the margin optimization in SVM. Considerations include whether to classify pixels or objects, the selection of the appropriate machine learning model, and the determination of necessary hyperparameters. Overall, this week’s lecture provided a comprehensive overview of classification methods in remote sensing and their application through machine learning."
  },
  {
    "objectID": "week_1.html#summary",
    "href": "week_1.html#summary",
    "title": "1  Week 1 - Basics",
    "section": "1.1 Summary",
    "text": "1.1 Summary\n\n1.1.1 What is Remote Sensing, you ask?\nRemote sensing is like Earth’s Personal Observer, capturing information from afar. NASA defines Remote Sensing as acquiring information from a distance - Earthdata-Website (2019) . Also, Elachi and van Zyl (2006) define remote sensing as “the acquisition of information about an object without being in physical contact with it”. All this is achieved through sensors mounted on satellites, planes, drones, etc.\n\n\n\nSpace Satellite GIF by NASA - GIPHY (n.d.)\n\n\n\n\n1.1.2 Types of Sensors ?\nRemote sensing employs two main types of sensors: Passive and Active.\nPassive sensors rely on sunlight reflected off the Earth’s surface. However, they are susceptible to interference from elements like clouds and atmospheric haze.\nActive sensors, on the other hand, emit signals directed towards the Earth, which bounce back to the satellite sensor. This allows active sensors to operate effectively at night and even penetrate through cloud cover, enhancing their versatility.\nThe choice between passive and active sensors depends on the specific environmental conditions and the type of data required for remote sensing applications. A basic difference of the two is shown in the below image explicitly\n\n\n\nDifference between passive and active sensors for remote sensing. Image © “The Nature Conservancy” (n.d.)\n\n\n\n\n1.1.3 Electromagnetic Spectrum ?\nRemote sensing is based on the principle that there is always an interaction between electromagnetic radiation and an object.Electromagnetic waves travel through the air and space, each with different wavelengths and frequencies. Some waves, like radio and infrared, have long wavelengths, while others, such as ultraviolet and x-rays, have short wavelength. Human eyes can only see a small part called visible light.\nDifferent types of radiation operate in various parts of the electromagnetic spectrum. Sensors can read different wavelengths, thus providing diverse information. Earth’s atmosphere blocks most wavelengths, allowing only radio waves, visible light, and some infrared. Instruments, like passive sensors in the optical window and active sensors using radio waves, help us understand our surroundings.\n\n\n\nElectromagnetic Spectrum, Source Earthdata-Website (2019)\n\n\n\n\n1.1.4 Resolutions\nRemote sensing data encompasses four key resolutions:\n\nSpectral Resolution: It refers to the size of each raster cell or pixel, dictating the level of detail captured.\nSpatial Resolution: It defines defines the sensor’s capability to differentiate wavelengths, determining the number of bands recorded, with multispectral sensors typically capturing 3-15 bands and hyperspectral sensors capable of thousands.\nTemporal Resolution:It indicates the frequency at which an area is revisited, influencing the timeliness of data acquisition.\nRadiometric Resolution: It quantifies the information contained within each raster cell, with higher resolutions yielding greater sensitivity to variations.\n\n\n\n\nDiagram showing different Resolutions, Source Darbari and Kumar (2022)"
  },
  {
    "objectID": "week_1.html#applications",
    "href": "week_1.html#applications",
    "title": "1  Week 1 - Basics",
    "section": "1.2 Applications",
    "text": "1.2 Applications\nRemote sensing data finds numerous applications across diverse fields. It is used in agriculture for optimizing uses of fertilizers, prediction of crop yields,measuring soil moisture content, monitoring droughts, assessment of crop health, etc.\n\n\n\nA split view comparing NDVI index values on the same field taken 5 days apart. Such a tremendous decrease in NDVI may be the result of water or heat stress, which can be tracked in EOSDA Crop Monitoring., Source\n\n\nSimilarly, in forestry it can be used for monitoring forest cover, tracking deforestation & controlling forest fires.Also, remote sensing is being used for checking the rapid urbanization, planning road networks, pre and post disaster preparedness & in many more fields.\n\n\n\nForest fire damage assessment in the Chillan region of Chile using remote sensing data and EOSDA LandViewer capabilities., Source “Remote Sensing By Satellite: Physical Basis, Principles, & Uses” (2023)\n\n\nAlso, during my research regarding the use of remote sensing, I came across one of the works which discussed the application of remote sensing in route planning for road projects in challenging terrain (Mishra (2015)). This study delved into the effectiveness of remote sensing and Geographic Information Systems (GIS) in mapping road infrastructure in rugged landscapes. Various factors influencing road network construction and the resolution of associated challenges were examined within a specific context. Criteria encompassing major and subsidiary factors were assessed to select an appropriate model for comparing attributes and grading them based on their significance. All these examples together demonstrate how valuable remote sensing technology is across a wide range of fields."
  },
  {
    "objectID": "week_1.html#reflections",
    "href": "week_1.html#reflections",
    "title": "1  Week 1 - Basics",
    "section": "1.3 Reflections",
    "text": "1.3 Reflections\nTransitioning from a Civil Engineering background to the realm of spatial science, particularly remote sensing, has been a thrilling journey. One notable application that resonates with me, especially concerning India, is the utilization of remote sensing for identifying “Unconnected Habitations.” These are isolated dwellings or small clusters of houses situated in regions lacking road access, electricity, and water supply. Typically nestled in mountainous terrains, these areas are predominantly inhabited by tribal communities. So, by leveraging remote sensing technology we could identify these remote settlements, facilitating the formulation of targeted policies aimed at fostering development within these underserved regions.\n\n\n\n\nDarbari, Priyanka, and Manoj Kumar. 2022. “Satellite Image Enhancement Techniques: A Comprehensive Review.” In Proceedings of International Conference on Communication and Artificial Intelligence, edited by Vishal Goyal, Manish Gupta, Seyedali Mirjalili, and Aditya Trivedi, 431–47. Lecture Notes in Networks and Systems. Singapore: Springer Nature. https://doi.org/10.1007/978-981-19-0976-4_36.\n\n\nEarthdata-Website. 2019. “What Is Remote Sensing? | Earthdata.” Backgrounder. Earth Science Data Systems, NASA. August 23, 2019. https://www.earthdata.nasa.gov/learn/backgrounders/remote-sensing.\n\n\nElachi, Charles, and van Zyl Jakob J. 2006. “Introduction to the Physics and Techniques of Remote Sensing.” In Introduction to the Physics and Techniques of Remote Sensing, 1–21. Hoboken, NJ, USA: John Wiley & Sons, Inc.\n\n\nGIPHY, dir. n.d. Space Satellite GIF by NASA - Find & Share on GIPHY. Accessed February 4, 2024. https://giphy.com/gifs/nasa-space-nasagif-3ohc0PkM8mVYfmBHz2.\n\n\nMishra, Anoop Kumar. 2015. “A Study on the Occurrence of Flood Events over Jammu and Kashmir During September 2014 Using Satellite Remote Sensing.” Natural Hazards 78 (2): 1463–67. https://doi.org/10.1007/s11069-015-1768-9.\n\n\n“Remote Sensing By Satellite: Physical Basis, Principles, & Uses.” 2023. April 7, 2023. https://eos.com/blog/remote-sensing/.\n\n\n“The Nature Conservancy.” n.d. Accessed February 4, 2024. https://reefresilience.org/management-strategies/remote-sensing-and-mapping/introduction-to-remote-sensing/what-is-remote-sensing/."
  },
  {
    "objectID": "week_4.html#summary",
    "href": "week_4.html#summary",
    "title": "4  Week 4 - Policy",
    "section": "4.1 Summary",
    "text": "4.1 Summary\nThis week, we delved into Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets. GEE simplifies high-performance computing for researchers, facilitating sharing of results with various stakeholders. It offers an API and web-based IDE for quick prototyping and visualization. Instead of downloading heavy satellite imagery, GEE can swiftly load datasets, including various types of satellite imagery, via its Data Catalog. GEE operates on client-side code execution, enhancing speed, and utilizes JavaScript. It distinguishes between raster data (images) and vector data (features), organizing them into Image Collections and Feature Collections, respectively."
  },
  {
    "objectID": "week_5.html#summary",
    "href": "week_5.html#summary",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.1 Summary",
    "text": "5.1 Summary\nThis week was for Google Earth Engine (GEE), a cloud-based platform for accessing and processing large geospatial datasets.\n\nWhat is GEE?\n\nGEE is a cloud-based platform for processing large geospatial datasets.\nIt simplifies data access and analysis for researchers, policymakers, NGOs, and the public.\nGEE uses an API and web-based IDE for rapid prototyping and visualization.\nKey terminology includes objects (vectors, rasters, features), images (raster data), and geometries (points, lines, polygons).\n\nFunctionalities\n\nGEE facilitates spatial operations, machine learning tasks, and statistical analyses.\nIts functionalities include reducing imagery, accessing data from multiple sensors, and performing joins and intersections.\n\n\nLast year, shortly after arriving in London, one of my initial tasks was to explore the evolution of Canary Wharf from its roots as docks to its current status as a financial hub. I connected to the city a lot more after this exposure of the history. Let us look at the transformation of Canary Wharf from its origins as dockyards to becoming a bustling business district.You can witness this evolution through Google Timelapse “Google Timelapse” (n.d.), one of the products of GEE. Simply press play button to observe the journey through time"
  },
  {
    "objectID": "week_5.html#applications",
    "href": "week_5.html#applications",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.2 Applications",
    "text": "5.2 Applications\nThere have been so advancment in remote sensing research and ease of doing research with satellite data because of GEE. So, I made a tree map of “What is the craze about GEE and which sectors has it impacted”.\n\n\n\nGEE the bridge that connects, Source - Author"
  },
  {
    "objectID": "week_5.html#reflections",
    "href": "week_5.html#reflections",
    "title": "5  Week 5 - Google Earth Engine",
    "section": "5.3 Reflections",
    "text": "5.3 Reflections\nGEE presents an intriguing tool for analysis, showcasing the impressive strides in technology and data analysis. Its ability to swiftly process vast amounts of data quickly as compared to tools like SNAP and R, make it exceptionally useful and futuristic. The versatility of GEE is evident in its extensive data access and diverse range of applications, spanning from straightforward to intricate processing tasks. I firmly believe that GEE and cloud computing will revolutionize remote sensing research. Despite my prior experience in Python and R, exploring a new coding language like JavaScript piques my interest, prompting me to consider further learning opportunities.But, again, this entire course of MSc Urban Spatial Science has been an opportunity to go to uncharted territories and moving away from your comfort zone. And despite the demanding nature of the course, this exploration has been immensely enriching, largely thanks to the outstanding faculty at CASA, whom I consider are among the finest at Bartlett.\n\n\n\n\n“Google Timelapse.” n.d. Accessed March 9, 2024. https://earthengine.google.com/timelapse/."
  },
  {
    "objectID": "week_3.html#applications",
    "href": "week_3.html#applications",
    "title": "3  Week 3 - Corrections",
    "section": "3.2 Applications",
    "text": "3.2 Applications\nThis week’s session focused on rectifying raw satellite images, merging them, and enhancing their quality, particularly delving into the significance of atmospheric corrections in satellite image studies. It’s crucial to recognize that satellite images often suffer from distortions due to various factors which were discussed above, and these can compromise the accuracy of our analysis. To mitigate these distortions, the corrections are routinely applied as a prerequisite before conducting analysis. These corrections ensure that the images are properly aligned and scaled, laying a reliable groundwork for subsequent interpretation and extraction of meaningful data.\nI stumbled upon a research paper by Hassan et al. (2006), where they delve into examining how changes in the number of Ground Control Points (GCPs) and the degree of mapping polynomials affect the accuracy of the geometric correction process. They utilized the Root Mean Square Error (RMS) at the chosen GCPs to gauge the accuracy of their findings. The study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.\n\n\n\na & b – Shows the raw image2 and its corresponding reference image, c & d – 4 GCPs distribution on raw image2 and its reference, e & f – corrected image2, and its reference,Source:Hassan et al. (2006)\n\n\nSimilarly, the same image was corrected by using 16 Ground Control Points as shown below.\n\n\n\na & b – shows the raw image2 and its corresponding reference image, c & d – 16 GCPs distribution on raw image2 and its reference, e & f – corrected image2, and its reference, Source Hassan et al. (2006)\n\n\nThe study revealed that employing a higher degree of polynomial rectification alongside an increased number of GCPs resulted in elevated RMS errors.The results of the study with respect to GCP, RMS is shown below.\n\n\n\nAverage of RMS error of all test images at each order of polynomials, Source Hassan et al. (2006)"
  },
  {
    "objectID": "week_3.html#reflections",
    "href": "week_3.html#reflections",
    "title": "3  Week 3 - Corrections",
    "section": "3.3 Reflections",
    "text": "3.3 Reflections\nAs I joined the Term quite late, so had to catch up with all in a short amount of time. But, as the lectures and the practical notebooks were crafted perfectly, so I was able to grasp most of the concepts. Regarding, this week, I understand the importance of covering corrections, despite their initial complexity, to ensure data quality and facilitate comparison between different images. Exploring how remotely sensed images can be manipulated reveals deeper layers of information beyond the surface data. Although I didn’t do the practical exercises this week, but I have gone through the code and have also checked the Ahmad (n.d.) as recommended & I found it valuable and I anticipate revisiting it in future.\n\n\n\n\nAhmad, Dr. Zia. n.d. “Geospatial Data Science in R.” Accessed March 9, 2024. https://zia207.github.io/geospatial-r-github.io/index.html.\n\n\nHassan, Fawzy, Gouda Salama, Esam Hamza, and H. Hussien. 2006. “GEOMETRIC CORRECTION OF REMOTE SENSING SATELLITE DIGITAL IMAGES USING MAPPING POLYNOMIAL OF DIFFERENT ORDERS.” The International Conference on Electrical Engineering 5 (5): 1–22. https://doi.org/10.21608/iceeng.2006.33672."
  },
  {
    "objectID": "week_3.html#summary",
    "href": "week_3.html#summary",
    "title": "3  Week 3 - Corrections",
    "section": "3.1 Summary",
    "text": "3.1 Summary\n\n3.1.1 Corrections\nRemotely sensed data requires corrections to remove flaws which may be due to various factors like - atmosphere, sensor sensitivity, illumination conditions, distortions due to viewing angle,topographic conditions,etc.\n- Atmospheric Correction: It removes flaws caused in the remotely sensed data due to atmosphere.The atmosphere affects the incoming sunlight thereby leading to reflection, scattering and absorption of various parts of electromagnetic spectrum. Atmospheric correction is either relative or absolute. Relative atmospheric correction adjusts the data based on radiance values of target area with respect to neighboring area, while as, in absolute atmospheric correction we convert digital brightness values into scaled surface reflectance. This allows us to directly compare these scaled surface reflectance values across different regions of the planet, facilitating accurate analysis and interpretation of Earth’s surface characteristics and changes over time.\n- Geometric Correction: Geometric correction involves adjusting remotely sensed data to account for image distortions introduced by various factors such as the view angle (off-nadir), topography (e.g., non-flat terrain), wind (in aerial acquisitions), and the rotation of the Earth (in satellite imagery). This correction ensures that the satellite image aligns accurately with a coordinate reference system.\n- Topographic Correction: It deals with the effect of terrain variations on reflectance values.It requires sensor geometry and elevation data. After incorporating it, the accuracy and consistency of remote sensing data improves across different terrain conditions.\n- Radiometric Correction: This correction accounts for sensor-related factors such as variations in sensor sensitivity, illumination conditions, and atmospheric effects, ensuring that the resulting data accurately represents the physical properties of the observed features."
  },
  {
    "objectID": "week_6.html#summary",
    "href": "week_6.html#summary",
    "title": "6  Week 6 - Classification",
    "section": "6.1 Summary",
    "text": "6.1 Summary\nClassification in remote sensing involves categorizing pixels in imagery to label them based on land cover use or other characteristics. This process is integral to various data processing pipelines and is commonly used for identifying urban areas, vegetation, and other land uses. This week’s lecture focused on classification in remote sensing and its implementation using machine learning techniques.Machine learning methods discussed include classification and regression trees (CART), random forests, maximum likelihood, and support vector machine (SVM). The lecture also covered supervised and unsupervised image classification approaches. Each classification method has its own principles and considerations, such as the need for human knowledge in expert systems, the use of decision rules in maximum likelihood classification, and the margin optimization in SVM. Considerations include whether to classify pixels or objects, the selection of the appropriate machine learning model, and the determination of necessary hyperparameters. Overall, this week’s lecture provided a comprehensive overview of classification methods in remote sensing and their application through machine learning."
  }
]